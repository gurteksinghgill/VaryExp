---
title: |
  A Universal Algorithm for Continuum Limit Distributions of Continuous
  Time Random Walks
author:
  - name: Gurtek Gill
    email: rickygill01@gmail.com
    affiliation: UNSW Sydney
  - name: Peter Straka
    email: p.straka@unsw.edu.au
    affiliation: UNSW Sydney
    footnote: Corresponding Author
address:
  - code: UNSW Sydney
    address: School of Mathematics & Statistics, Sydney, NSW 2052, Australia
abstract: |
  We propose a universal "Semi-Markov algorithm" for the computation of
  probability distributions of Continuous Time Random Walks (CTRWs) and their
  continuum limits.
  The algorithm is universal in the following sense: Any CTRW continuum limit
  can be mapped to a bivariate Langevin equation which tracks the cumulative sum
  of jumps and waiting times, and given the coefficients of this Langevin
  equation, the algorithm will compute the desired probability distributions.
  Besides subdiffusion with space- and time-dependent drift, this approach
  covers subdiffusion with spatially varying exponent $\beta(x) \in (0,1)$ and
  tempering parameter $\theta(x) \ge 0$, and subdiffusion with mixed (distributed)
  order where the mixture can vary in space.
  Our Semi-Markov algorithm generalizes the recent
  "Discrete Time Random Walk" algorithm, and shares the same properties:
  it is consistent, conserves mass, generates strictly non-negative solutions,
  and has the same computational complexity.
  To illustrate applicability, we set up an interface problem, where two
  subdiffusive media with different anomalous exponents meet, and compute the
  evolution of probability densities at the interface.
journal: "An Elsevier Journal"
date: "`r Sys.Date()`"
bibliography: varyExp.bib
output:
  rticles::elsevier_article:
    number_sections: true
preamble: |
  \usepackage{amsthm,amsmath,amssymb,hyperref}
---

\newtheorem{lemma}{[theorem]{Lemma}}

# Introduction

Subdiffusive transport processes are characterized via a sublinear growth of the
mean squared displacement: $\langle X_t \rangle \sim t^\alpha$, where
$0 < \alpha < 1$. Such processes are usually modelled either by fractional
Brownian motion or Continuous Time Random Walks (CTRWs), depending on
whether the auto-correlation of jumps decays slowly or the waiting times
between jumps are heavy-tailed with parameter $\alpha$, modelling traps
or dead ends [@HLS2010b].
The CTRW model has proven to be a particularly useful model, predominantly in
biophysics
[@Metzler2000; @TMT04; @Wong04; @Banks2005; @Santamaria2006a; @Hofling2012; @Regner2013],
but also in groundwater hydrology [@Berkowitz2008; @SchumerMIM] and
econophysics [@Scalas2006].

A modelling framework for the evolution of probability densities of random walks
is given by the Fokker--Planck equation [@gardiner2004handbook]:
\begin{align}
\frac{\partial P(y,t)}{\partial t} = \mathcal L^*(y,t) P(y,t) + \delta_{(0,0)}(y,t),
\end{align}
where
\begin{align}
\mathcal L^* g(y,t)
&= -\frac{\partial }{\partial y}[b(y,t) g(y,t)]
+\frac{1}{2}\frac{\partial^2 }{\partial y^2}[a(y,t) g(y,t)]
\end{align}
is called the Fokker--Planck operator.
CTRWs generalize random walks by allowing a larger, heavy-tailed
class of waiting times before each jump. This translates into a
_memory kernel_ $V(y,t)$
acting on the time variable in the equation [@BaeumerStraka16]:
\begin{align}
\frac{\partial P(y,t)}{\partial t} = \mathcal L^*(y,t) \left[ \frac{\partial}{\partial t}
\int_0^t P(y,t-s) V(y,s)\,ds \right] + \delta_{(0,0)}(y,t).
\label{eq:FFPE}
\end{align}
The table below gives an overview over frequently studied forms of
$V(y,s)$:

|                       | Kernel        | Laplace Transform | Reference |
| ------:               | :-------------: |:-------------:| :--------------: |
| no memory             | $1$                             | $\lambda^{-1}$ |
| subdiffusion          | $s^{\alpha-1} / \Gamma(\alpha)$ | $\lambda^{-\alpha}$ | @Sokolov2006e |
| tempered subdiffusion | unknown | $((\lambda + \theta)^\alpha - \theta^\alpha)^{-1}$ | @Gajda2010 |

As the table indicates, most researchers have studied spatially constant
memory kernels, without any dependence on the space variable $y$.
This implies a homogeneous distribution of waiting times throughout the
entire medium, i.e. that diffusion is equally
anomalous everywhere.  This assumption is of course too restrictive for some
applications in biophysics [@Wong04; @StrakaFedotov14], e.g. when trapping 
varies due to locally different compositions of the cellular matrix.
Moreover, media with two
different anomalous exponents exhibit interesting, paradoxical behaviour
[@Korabel2010; @Straka17], and have been studied (analytically) in the
physics literature [@Stickler2011; @Fedotov2012].

Numerous methods for the computation of solutions to
_homogeneously anomalous_ diffusion have been developed, among them explicit
methods [@Yuste2005], implicit methods [@Langlands2005a], spectral methods
[@Li2009; @Hanert2014] and Galerkin methods [@Mustapha2011].
In the domain of _inhomogeneously anomalous_ diffusion, several authors
have developed computational methods for _variable order_ fractional Fokker--Planck Equations, but only the equation studied by @Chen2010
is consistent with a CTRW scaling limit representation [@Straka17].

The algorithm we introduce in this paper computes solutions to all
Fokker--Planck equations of type \eqref{eq:FFPE}
with spatially varying memory.  Its only requirement is that the
coefficients of the underlying bivariate Langevin process $(Y_u, Z_u)$,
which tracks the cumulative sum of jumps resp. waiting times,
can be evaluated numerically.

Similarly to the Discrete Time Random Walk (DTRW) method
[@Angstmann2015a; @Angstmann2016a], our algorithm calculates the
probability distributions of a CTRW whose waiting times are grid-valued, 
and which approximates the continuum limit process.
The advantages of this approach are that mass is necessarily conserved
in each timestep; that solutions are guaranteed to be nowhere
negative; and that stochastic process convergence implies the
consistency of the algorithm.
However, we do not rely on discrete Z-transforms, which means that
our method remains tractable not just for Shibuya-distributed waiting
times.

In the rest of this paper: 
We give a short account of bivariate Langevin dynamics
and their relevance for this article in Section 2.
In Section 3 we construct a sequence of DTRWs which converges to
a CTRW continuum limit process, represented by a general bivariate
Langevin equation $(Y_u, Z_u)$.
The stochastic process convergence guarantees the convergence of
probability distributions to the solutions $P(y,t)$ of
\eqref{eq:FFPE}, which translates into the consistency of the algorithm.
In Section 4 we calculate the probability distributions of the DTRW.
Because of the Semi-Markov property, this can be done via genearlized
master equations in a higher dimensional state space which tracks the
time since the last jump.
In Section 5 we consider an interface problem, where the anomalous
exponent interpolates continuously between two different anomalous
exponents for each half axis. Section 6 concludes.



# Stochastic solution to Fokker-Planck equation with memory

The Langevin representation of a stochastic process whose distribution 
$P(y,t)$ solves a Fokker-Planck equation with memory has been studied in 
various articles [@Weron2008; @HLS10PRL; @Gajda2010; @Hahn11]. 
Recently, a Langevin representation for inhomogeneous anomalous diffusion 
was given [@Straka17]: Consider the bivariate Langevin process with state 
space $\mathbb R \times [0,\infty)$

\begin{align}
dY_u &= b(Y_u, Z_u)\, du + \sqrt{a(Y_u, Z_u)} \, dW_u 
\label{eq:dY}\\
dZ_u &= d(Y_u) \, du + \int_{w > 0} w\, n(dw, du)
\label{eq:dZ}
\end{align}

Here, $u$ is auxiliary time, corresponding to the number of jumps;
$b(y,t)$ and $a(y,t)$ are drift and diffusivity coefficients 
(of units length resp. length$^2$ per unit _auxiliary time_) appearing in 
\eqref{eq:FFPE}; 
$d(y)$ is a temporal drift coefficient
(unit physical time per unit auxiliary time). 
Finally, $n(dw, du)$ denotes Levy noise that can be spatially varying. 
Recall that Levy noise has a representation as a Counting Measure, 
where for any rectangle 
$R = (u_1, u_2) \times (w_1, w_2) \subset [0,\infty) \times (0,\infty)$ 
the number of points $n(R)$ in $R$ is Poisson distributed, 
and independent of any counts in other, disjoint rectangles [@Applebaum]. 
The Poisson distribution, and hence the entire Counting Measure, is governed 
by a unique mean measure $m(dw, du)$ which satisfies 
$m(R) = \langle n(R) \rangle$. Examples:

* If 
$m(R) = (u_2 - u_1) \times \int_{w_1}^{w_2} \frac{\beta w^{-1-\beta}}{\Gamma(1-\beta)}\, dw$,
then $Z_u$ has independent and identically distributed increments, i.e. it is 
a Levy flight. 

* Letting $m(R) = (u_2 - u_1) \times \int_{w_1}^{w_2} \frac{\beta w^{-1-\beta} e^{-\theta w}}{\Gamma(1-\beta)}\, dw$
results in $Z_u$ being a _tempered stable Levy flight_ with tempering parameter 
$\theta \ge 0$. 

A dependence of the Levy measure on the position $Y_u$ of the walker can be 
achieved via letting 
$$
m(R) = \int_{u_1}^{u_2} \nu((w_1, w_2] |Y_u)\, du
$$

for some _Levy measure_ $\nu(dw | y)$, which may vary with $y$. 
Recall that a Levy measure is defined by the requirement 
$$
\int_0^\infty \min\{1, w\} \nu(dw | y) < \infty.
$$
For instance, letting the fractional exponent $\beta(y) \in (0,1]$ depend on space, 
choosing $\nu(dw | y) = \frac{\beta(y) w^{-1-\beta(y)}}{\Gamma(1-\beta(y))}\,dw$
results in $Z_u$ having independent increments, which follow the stable distribution
with exponent $\beta(Y_u)$ [@Straka17].

It will be convenient to introduce the tail function of the Levy measure 
$$
\overline \nu(w | y) := \int_w^\infty \nu(dw | y), \quad w > 0.
$$
and its Laplace transform 
$$
\hat{\overline \nu}(\lambda | y) = \int_0^\infty \overline \nu(w|y)\,e^{-\lambda w}\,dw.
$$
We note that the 4-tuple $\left(a(y,t), b(y,t), d(y), \overline \nu(w, y)\right)$
uniquely and concisely represents the Langevin process
\eqref{eq:dY}--\eqref{eq:dZ}.

Finally, we define the _renewal function_ $V(y,s)$ via its Laplace transform
$$
\hat V(y,\lambda) := \int_0^\infty V(y,s)\,e^{-\lambda s}\,ds
= \frac{1}{\lambda [d(y) + \hat{\overline \nu}(\lambda | y)]}
$$
As shown by @BaeumerStraka16, the Fokker--Planck equation with memory 
\eqref{eq:FFPE} has, under certain continuity conditions on the four coefficient 
functions, a unique solution $P(y,t)$. 
This solution coincides with the probability distribution at time $t$ 
of the subordinated process 
$$
X_t := Y_{E(t)}, \quad E(t) := \inf\{u: Z_u > t\}.
$$


# Discrete Langevin Dynamics

Let $c > 0$ be a scaling parameter, and define a spatio-temporal grid $\#$
with spacings $\chi = c^{-1/2}$ and $\tau^{-1/\alpha_0}$, where 
$\alpha_0 \in (0,1)$ is some reference value to be defined later. 
Assuming for simplicity that space is one-dimensional, the grid is embedded 
in space-time $\mathbb R \times [0, \infty)$. 
In this section we define for each $c > 0$ a Langevin process 
$(Y^{(c)}_u, Z^{(c)}_u)$ with state space $\#$ such that as $c \to \infty$, 
$(Y^{(c)}_u, Z^{(c)}_u)$ converges to $(Y_u, Z_u)$. 

It is clear that $(Y^{(c)}_u, Z^{(c)}_u)$ is a jump process; 

\subsection{Waiting time distribution}

The discrete waiting time distribution $\psi^{(c)}(w|x)$ we will define now will be supported on the points $\tau, 2\tau, 3\tau, \ldots$ where $\tau = 1/c$.
We use an upper bar for the tail functions of the L\'evy measure
\eqref{eq:Levy-measure} and the waiting time distribution $\psi^{(c)}(w|x)$:
\begin{align}
  \overline \nu(w|y) = \int_w^\infty \nu(w'|y)\,dw',
  \quad
  \overline \psi^{(c)}(w|x) = \sum_{w' = j\tau,\, w' > w} \psi^{(c)}(w'|x),
  \quad w > 0.
\end{align}
For convenience, we use the convention that $\overline \nu(w|y) = \infty$ for $w \le 0$.  We first define the tail function of a continuous probability measure via
\begin{align}
  H^{(c)}(w | y) := 1 \wedge \left[\tau \overline \nu\left(w - \tau d(y)\right)\right], \quad w > 0.
\end{align}
For $w>0$, let $w_\tau$ be the nearest lattice point which is not smaller; i.e.\
\begin{align} \label{eq:w-tau}
w_\tau = j\tau \ge w > (j-1)\tau,
\end{align}
and take the piecewise constant,
right-continuous and non-increasing function
\begin{align}
  \overline\psi^{(c)}(w|y) := H^{(c)}(w_\tau|y), \quad w \ge 0
\end{align}
to be the tail probability function which defines $\psi^{(c)}(w|y)$.
Equivalently, we have
\begin{align} \label{eq:def-psi}
  \psi^{(c)}(j\tau | y) = H^{(c)}((j-1)\tau | y) - H^{(c)}(j\tau | y).
\end{align}
Note that $\psi^{(c)}(0\tau | y) = 0$, i.e.\ waiting times are strictly positive.


\subsection{Preliminary calculations}

We need to calculate two sums which will be useful for checking conditions
\eqref{eq:cond3} \& \eqref{eq:cond4} below.

\begin{lemma}
The waiting time distribution \eqref{eq:def-psi} satisfies, as $c \to \infty$,
\begin{align}
\label{eq:psi2delta}
\int f(w) \psi^{(c)}(w|y)\,dw = \sum_{j = 1}^\infty f(j\tau) \psi^{(c)}(j\tau|y)
&\to f(0),
\\ \label{eq:psi-non-local}
c \int g(w) \psi^{(c)}(w|y)\,dw
= c \sum\limits_{j\tau > 0} g(j\tau) \psi^{(c)}(j\tau|y)
&\to \int g(w) \nu(w|y)\,dw,
\\ \label{eq:psi-local}
c \int_0^\varepsilon w \psi^{(c)}(w|y)\,dw
= c \sum\limits_{0 < j\tau \le \varepsilon} j\tau \psi^{(c)}(j\tau | y)
&\to d(y)
%- \varepsilon \overline{\nu}(\varepsilon)
%+ \int_0^\varepsilon \overline{\nu}(w)\,dw,
+ \mathcal O(\varepsilon^{1-\beta(y)}), \quad \varepsilon > 0.
\end{align}
where $f$ and $g$ are bounded continuous, and where $g$ vanishes in a neighbourhood of $0$.
\end{lemma}

#### Proof
\eqref{eq:psi2delta} holds since $\psi^{(c)}(w|y)$ is a probability distribution on the positive numbers and $\overline \psi^{(c)}(w|y) \to 0$ as $c \to \infty$ for all $w > 0$.
For \eqref{eq:psi-non-local}, we first note that
\begin{align*}
c \overline \psi^{(c)}(w|y)
= c \wedge [\overline \nu(w - \tau d(y))] \to \overline \nu(w).
\end{align*}
If $g$ is differentiable, we may calculate
\begin{align*}
c \int_0^\infty g(w) \psi^{(c)}(w|y)\,dw
= c \int_\varepsilon^\infty g(w) \psi^{(c)}(w|y)\,dw
= c \int_\varepsilon^\infty g'(w) \overline \psi^{(c)}(w|y)\,dw
\\
\to \int_\varepsilon^\infty g'(w) \overline \nu(w|y)\,dw
= \int_\varepsilon^\infty g(w) \nu(w|y)\,dw
= \int_0^\infty g(w) \nu(w|y)\,dw
\end{align*}
But differentiable functions lie dense in the space of bounded continuous functions, so \eqref{eq:psi-non-local} follows.
For \eqref{eq:psi-local},
first note that
\begin{align*}
1 = H^{(c)}(w|y)
\Longleftrightarrow
w \le \overline \nu^{-1}(c|y) + d(y)\tau =: C(y,c).
\end{align*}
Hence we have $j\tau \le C(y,c) \Longrightarrow \psi^{(c)}(j\tau|y) = 0$.
We let $n_1 = \lfloor C(y,c) / \tau \rfloor$ and
$n_2 = \lfloor \varepsilon / \tau \rfloor$.
Then by assumption \eqref{eq:ass4},
\begin{align}
\overline \nu(c|y)^{-1} \sim \Gamma(1-\beta(y)) c^{-1/\beta},
\quad c \to \infty,
\end{align}
and hence
\begin{align} \label{eq:to-dy}
\lim_{c \to \infty} \tau n_1 c = \lim_{c \to \infty} \tau \overline \nu^{-1}(c | y) + d(y) = d(y)
\end{align}
Then the left side of \eqref{eq:psi-local} is
\begin{align*}
&c \sum_{C(y,c) < j\tau \le \varepsilon} j\tau \psi^{(c)}(j\tau | y)
= c \sum_{j=n_1}^{n_2} j\tau \left[ H^{(c)}(j\tau | y) - H^{(c)}((j+1)\tau | y)\right]
\\
&= c n_1 \tau H^{(c)}(n_1 \tau | y) - c (n_2+1) \tau H^{(c)}((n_2+1) \tau | y)
+ \tau \sum_{j=n_1}^{n_2} cH^{(c)}(j\tau)
\end{align*}
where for the second equality sign, we have splitted the sum in two, shifted the index in the second resulting second sum, and simplified the result.
In the first term of the result, we have $H^{(c)}(n_1 \tau | y) = 1$ and \eqref{eq:to-dy}.  For the second term, note that $n_2 \tau \to \varepsilon$, and
$c H^{(c)}(w|y) \to \overline \nu(w)$ for every $w > 0$.
And finally, the last term is seen to be the Riemann sum of an integral. Keeping in mind that as $c \to \infty$, $C(y,c) \downarrow 0$ and again that $c H^{(c)}(w|y) \to \overline \nu(w)$, the above converges to
\begin{align*}
d(y) - \varepsilon \overline \nu(\varepsilon | y)
+ \int_0^\varepsilon \overline \nu(w)\,dw,
\end{align*}
which is $d(y) + \mathcal O(\varepsilon^{1-\beta(y)})$ due to \eqref{eq:ass4}.



\subsection{Jump distribution}

We assume that the DTRW jumps can have one of the three values
$\{-\chi, 0, +\chi\}$, where $\bar a = \sup\{a(x,t)\}$ and $\chi = (\bar a / c)^{1/2}$.
The probabilities to jump left, to ``self-jump'' (i.e.\ jump back to the
original location), and to jump right, are given by
\begin{gather*}
\ell^{(c)}(x,t) = \frac{a(x,t) - \chi b(x,t)}{2 \bar a},
\quad
n(x,t) = 1 - a(x,t)/\bar a,
\quad
r^{(c)}(x,t) = \frac{a(x,t) + \chi b(x,t)}{2 \bar a}.
\end{gather*}
where $x$ is the location of the walker before the jump, and $t$ is the time at which the jump occurs.
In order for $r, n$ and $\ell$ to be between $0$ and $1$,
we need $\chi$ to be small  enough so that
\begin{align}
  \chi |b(x,t)|  \le a(x,t), \quad (x,t) \in \mathbb R \times [0,\infty).
\end{align}
For later use, we note that
\begin{align}
\label{eq:jump-calc-b}
c [-\chi \ell^{(c)}(x,t+w) + \chi r^{(c)}(x,t+w)]
&= b(x,t+w)
\\ \label{eq:jump-calc-a}
c \chi^2 [\ell^{(c)}(x,t+w) + r^{(c)}(x,t+w)] &= a(x,t+w)
\\ \label{eq:jump2delta}
\int_\mathbb R f(z)\left[r^{(c)}(x,t) \delta_\chi(z)
+ n(x,t) \delta_0(z) + \ell^{(c)}(x,t) \delta_{-\chi}(z) \right]\,dz
&\to f(0)
\end{align}
as $c \to \infty$ for all bounded continuous $f$.


\subsection{Conditions \eqref{eq:cond1} -- \eqref{eq:cond4}}

Assume now that a jump happens at time $t$ and the location of the walker immediately after the jump is $(x,t)$.
Then the next jump will happen at time $t+w$, where $w$ is drawn from $\psi^{(c)}(w|y)$, and it is common to evaluate the probabilities to jump left/right/self-jump at time $t+w$.  In this case the space-time transition kernel governing the DTRW is
\begin{align} \label{eq:DTRWSTJK}
  K^{(c)}(z,w|x,t) = \left[r^{(c)}(x,t+w)\delta_{+\chi}(z)
  + n(x, t+w) \delta_0(z)
  + \ell^{(c)}(x, t+w) \delta_{-\chi}(z)\right]
  \psi^{(c)}(w|x).
\end{align}
Alternatively, one may assume that the bias to jump left/right/self-jump is evaluated at the \emph{beginning} of a waiting time, which leads to
\begin{align} \label{eq:DTRWSTJK2}
  K^{(c)}(z,w|x,t) = \left[r^{(c)}(x,t)\delta_{+\chi}(z)
  + n(x, t) \delta_0(z)
  + \ell^{(c)}(x, t) \delta_{-\chi}(z)\right]
  \psi^{(c)}(w|x).
\end{align}
These dynamics were considered in @Angstmann2015, where it was already found that \eqref{eq:DTRWSTJK} and \eqref{eq:DTRWSTJK2} yield the same CTRW limit process.  Indeed, both kernels satisfy conditions \eqref{eq:cond1}--\eqref{eq:cond4}.

To see that \eqref{eq:cond1}--\eqref{eq:cond2} hold, use
\eqref{eq:jump-calc-b}--\eqref{eq:jump-calc-a} and \eqref{eq:psi2delta}. To see \eqref{eq:cond3}, use \eqref{eq:psi-local} and let $\varepsilon \downarrow 0$; and finally, to see \eqref{eq:cond4}, use \eqref{eq:psi-non-local} and \eqref{eq:jump2delta}.





# Semi-Markov numeric scheme

\subsection{Master equations}

In the previous section, we have constructed a DTRW $X^{(c)}_t$ which  converges to the CTRW limit $X_t$ whose densities $P(y,t)$ solve \eqref{eq:FFPE}.  For large values of $c$, the probability densities of $X^{(c)}_t$ will hence be a good approximation of $P(y,t)$, see \eqref{eq:consistency} below.
In this section, we calculate the probability distributions of $X^{(c)}_t$.

Consider the space-time transition kernel \eqref{eq:DTRWSTJK} which defines the DTRW. Since all jumps are from $\{-\chi, 0, +\chi\}$, the walker will be hopping on a lattice embedded in $\mathbb R$.
Recall that a waiting time $W$ at a spatial lattice point $i\chi$ is drawn from $\psi^{(c)}(w | i\chi)$ and thus satisfies
\begin{align}
\mathbf P(W > j\tau) = H^{(c)}(j\tau | i\chi) =: h_{i,j}.
\end{align}
Conditional on $W > j\tau$, the probability that $W > (j + 1) \tau$ is
$$\mathbf P(W > (j + 1)\tau | W > j \tau) = h_{i,j+1} / h_{i,j}.$$
We now write $(x_k,v_k) \in \mathbb Z \times (\mathbb N \cup \{0\})$ for the
lattice coordinates of a walker's location and age at time
$k\tau$. That is, $(x_k, v_k) = (i,j)$
means that at time $k\tau$, the walker is at $i \chi$, and has arrived there at time $(k-j)\tau$ (and not moved since).
Now if $(x_k, v_k) = (i,j)$, then by time $(k+1)\tau$ either
\begin{itemize}
\item
no jump has occured: then $(x_{k+1}, v_{k+1}) = (i,j+1)$, which happens
with probability $h_{i,j+1} / h_{i,j}$. Or,
\item
a jump has occured: then $(x_{k+1}, v_{k+1}) = (i + z, 0)$, which happens with
probability $1-h_{i,j+1} / h_{i,j}$, and independently
$z$ equals $+1$, $-1$ or $0$ with probabilities
$r^k_i = r^{(c)}(i\chi, (k+1)\tau)$, $\ell^k_i = \ell^{(c)}(i\chi, (k+1)\tau)$ or
$n^k_i = n(i\chi, (k+1)\tau)$, respectively.
\end{itemize}
The above dynamics uniquely determine the stepwise evolution of $(x_k, v_k)$.
We write
$\xi^k_{i,j} = \mathbf P(x_k = i, v_k = j)$
for the probability distribution of $(i,j)$ at time $k$.
The master equations for $\xi^k_{i,j}$ then read:
\begin{align}
\label{eq:GME1}
\xi^{k+1}_{i,j} &= \frac{h_{i,j}}{h_{i,j-1}}\, \xi^k_{i,j-1}, \quad 1 \le j < J-1,
\\
\label{eq:GME2}
\xi^{k+1}_{i,0} &= \sum_{j=0}^J\left(1 - \frac{h_{i,j+1}}{h_{i,j}}\right)
(\ell^k_{i+1} \xi^k_{i+1, j} + r^k_{i-1} \xi^k_{i-1,j}
  + n^k_{i,j} \xi^k_{i,j})
\end{align}
The line \eqref{eq:GME1} states that for a walker to have age $j \ge 1$,
it must have had age $j - 1$ in the previous time step, and not jumped.
The line \eqref{eq:GME2} states that for a walker to have age $j = 0$,
it must have jumped to its location $i$ in the previous time step, from a
neighbouring lattice site or from $i$ itself. The probability mass of all
walkers jumping from site $i$ during time step $k \to k+1$ is
$\sum_{j=0}^J \left(1 - h_{i,j+1} / h_{i,j}\right) \xi^k_{i,j}$,
which is redistributed according to the probabilities $r^{k+1}_{i,j}$,
$\ell^{k+1}_{i,j}$ and $c^{k+1}_{i,j}$.
This interpretation shows that \eqref{eq:GME1}--\eqref{eq:GME2}
\textbf{conserve probability mass}.

\subsection{Boundary conditions}
In practice, one can only allocate a finite number $J$ of points to the
lattice of ages.  If we cannot allocate
$\lfloor T/\tau \rfloor$ lattice points, where $T$ is the largest time of interest, then it is possible that the age of walkers may reach the end of the lattice. In this case, and if the walker does not jump in the next time step, we do not increase its age any further, until it eventually does jump:
\begin{align}
\xi^{k+1}_{i,J} = \frac{h_{i,J}}{h_{i,J-1}} \xi^k_{i,J-1}
+ \frac{h_{i,J+1}}{h_{i,J}} \xi^k_{i,J}.
\end{align}

Finally, assuming that the spatial coordinates of the lattice go from
$-I$ to $I$, we implement Neumann boundary conditions by placing a walker
back on the boundary whenever it would otherwise have jumped off the lattice,
that is:
\begin{align}
  \ell^k_{-I} &= 0, & n^k_{-I} &= \ell(-I\chi, k\tau) + n(-I\chi, k\tau),
  & r^k_{-I} &= r(-I\chi, k\tau),
  \\
  \ell^k_I &= \ell(I \chi, k\tau), & n^k_{I} &= n(I\chi, k\tau) + r(I\chi, k\tau),
  & r^k_{I} &= 0
\end{align}


\subsection{Properties of the algorithm}

The main interest lies in the probability distribution of $X^{(c)}_t$.
Since the temporal lattice $\{k\tau\}$ is embedded in $[0,\infty)$, we have
$X^{(c)}_t = X^{(c)}_{t_\tau}$, where $t_\tau$ is defined exactly as $w_\tau$ in \eqref{eq:w-tau}.  By marginalizing over the age $j$, we thus find
\begin{align}
  \mathbf P(X^{(c)}_t = i\chi) =: \rho^k_i = \sum_{j=0}^J \xi^k_{i,j},
  \quad k = \lfloor t /\tau \rfloor.
\end{align}


\paragraph{Positivity}
From \eqref{eq:GME1}--\eqref{eq:GME2}, it is evident that the $\xi^k_{i,j}$ are
necessarily non-negative, and hence the solution $\rho^k_i$ cannot be negative.


\paragraph{Consistency of the algorithm}
Due to \eqref{eq:CTRW-J1}, the convergence
\begin{align} \label{eq:consistency}
  \sum_{i=-I}^I f(i\chi) \rho^{\lfloor t/\tau \rfloor}_i
  = \langle f(X^{(c)}_t) \rangle
  \longrightarrow \langle f(X_t) \rangle
  \quad \text{ as } c \to \infty,
\end{align}
holds for all bounded continuous real-valued $f$ defined on $\mathbb R$.
Now if $X_t$ is Lebesgue absolutely continuous (has a density), then we may take $f$ to be an indicator function of an interval $(a,b)$, and \eqref{eq:consistency} reads
\begin{align}
  \sum_{a < i\chi < b} \rho_i^{\lfloor t / \tau \rfloor}
  \longrightarrow
  \mathbf P(a < X_t < b) \quad \text{ as } c \to \infty.
\end{align}


\paragraph{Equivalence with DTRW approach}  The Discrete Time Random Walk algorithm by
@Angstmann2015a assumes discrete waiting times with the Sibuya
distribution, whose tail function $\Psi(n)$ has the asymptotics
$\Psi(n) \sim n^{-\beta}$.
In \eqref{eq:GME2}, see that we have $\xi^k_{i,j} = \xi^{k-j}_{i,0} h_{i,j}$,
by telescoping \eqref{eq:GME1} and $h_{i,0} = 1$.  Hence
\eqref{eq:GME2} rewrites to
$$\xi^{k+1}_{i,0} = \sum_{j=0}^J (h_{i,j} - h_{i,j+1})
(\ell^{k+1}_{i+1} \xi^{k-j}_{i+1, 0} + r^{k+1}_{i-1} \xi^{k-j}_{i-1,0} + c^{k+1}_{i,j} \xi^{k-j}_{i,0}),$$
assuming that $h_{i,j}$ is constant in $i$ (homogeneous waiting times).
Since $h_{i,j} - h_{i,j+1}$ is the probability of a waiting time being
$j+1$, one sees the equivalence with Equation (16) in @Angstmann2015a,
if we choose $h_{i,j} = \Psi(j)$.

# Examples

\label{sec:examples}

Within this semi-Markov framework, we may now implement the above numeric scheme to calculate approximations of the densities of a variety of CTRW limits. By allowing for various initial residence times @Gill2016, waiting time distributions $\psi (\omega | x)$ and spatially varying exponents $\beta (x)$ these are able to model a very wide set of subdiffusive systems. \\

\paragraph{Spatially varying exponent}  For simplicity we let the coefficients $b \equiv 0$ and $d \equiv 0$. For the diffusivity we have $a(x) = T_0^{-\beta(x)}$ where $T_0$ is the time scale and waiting time distribution tail function $\Psi(x,t) = \frac{t^{-\beta(x)}}{\Gamma (1-\beta(x))}$. For the variable order $\beta(x)$ we consider a system where the subdiffusion slows down in one direction and speeds up in the other direction, defining $\beta(x) = 0.25 + 0.5/(1+e^{-x})$ so that $\lim_{x\to -\infty} \beta (x) = 0.25$ and $\lim_{x\to \infty} \beta (x) = 0.75$. Figure \ref{fig:varyexp1} shows the evolution of the density $P(x,t)$ at multiple times. The distinctive cusp shape of subdiffusion (with constant exponent) is present at small times, however the long-time behaviour shows the aggregation which begins to occur towards areas of smaller exponent $\beta(x)$ i.e. the particles aggregates towards and become trapped in the slower end of the system. \\

In @Korabel2010, the authors modelled a subdiffusive system with $\beta = 0.3$ for $x<0$ and $\beta = 0.75$ for $x>0$, while at the interface ($x=0$) the particles wait an exponentially distributed amount of time, and observed that in the long-time limit all particles end up in the left half. Here we consider a variable order system with $\beta (x) = 0.55e^{-x^2} + 0.15 + 0.5/(1+e^{-2x})$, noting that $\lim_{x\to -\infty} \beta (x) = 0.15$, $\lim_{x\to \infty} \beta (x) = 0.65$, while at the interface ($x=0$) the system is near-diffusive with $\beta = 0.95$. Figure \ref{fig:varyexp2} shows the evolution of the density $P(x,t)$ of the system. At small times we observe two peaks reflecting the trapping that occurs either side of the interface, however in the long-time we can see the aggregation of all particles towards the left hand side ($x<0$) which has lower exponent $\beta$. \\

\begin{figure}[h]
\includegraphics[scale=0.6]{../img/varyexp1}
\caption{\label{fig:varyexp1}
Density $P(x,t)$ at multiple times of a variable order subdiffusive system with $\beta(x) = 0.25 + 0.5/(1+e^{-x})$. The time scale $T_0 = 2$ and $c = 40$.}
\end{figure}

\begin{figure}[h]
\includegraphics[scale=0.6]{../img/varyexp2}
\caption{\label{fig:varyexp2}
Density $P(x,t)$ at multiple times of a variable order subdiffusive system with $\beta (x) = 0.55e^{-x^2} + 0.15 + 0.5/(1+e^{-2x})$. The time scale $T_0 = 2$ and $c = 40$.}
\end{figure}


\paragraph{Spatially varying Tempering}  The tempered Tail function is obtained by multiplying it by an exponential term $e^{-\theta  t}$. This yields the new Tail function $\Psi(x,t) = \frac{t^{-\beta(x)} e^{-\theta  t}}{\Gamma (1-\beta(x))}$ where $\theta \geq 0$ and we can see that this Tail function will now be integrable. Note that for $\theta = 0$ this reduces to the original tail function, and observe that for small $t$ and small $\theta$ dynamics of the system will still appear subdiffusive, while for large $t$ they will approach diffusive. Here we are now able to generalize this to allow the tempering parameter $\theta (x) \geq 0$ to be spatially varying so that the effect of this tempering may not be homogeneous throughout the system. Taking the variable order to be the same as in Figure \ref{fig:varyexp1} $\beta(x) = 0.25 + 0.5/(1+e^{-x})$, we consider the inhomogeneous tempering $\theta (x) = 1/(1+e^{0.5x})$. Figure \ref{fig:varytempering} illustrates the density $P(x,t)$ for this case, where we can see that particles begin to accumulate where tempering is low $(x>0)$. Noting that the variable exponent $\beta(x)$ is lower for $x<0$, this suggests that the effect of the tempering parameter $\theta (x)$ is stronger than that of $\beta(x)$. \\

\begin{figure}[h]
\includegraphics[scale=0.6]{../img/varytempering}
\caption{\label{fig:varytempering}
Density $P(x,t)$ at multiple times of a variable order subdiffusive system with spatially varying tempering. We set $\beta(x) = 0.25 + 0.5/(1+e^{-x})$ and $\theta (x) = 1/(1+e^{0.5x})$. The time scale $T_0 = 2$ and $c = 40$.}
\end{figure}


References {#references .unnumbered}
==========
